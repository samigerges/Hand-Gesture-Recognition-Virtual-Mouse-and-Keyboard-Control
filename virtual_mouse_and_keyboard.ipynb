{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a2d031b",
   "metadata": {},
   "source": [
    "# import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28fce646",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "import cv2 \n",
    "import time \n",
    "import pyautogui\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708f46d6",
   "metadata": {},
   "source": [
    "# Hand Detector and Button Class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bec38c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HandDetector:\n",
    "    def __init__(self):\n",
    "        self.mp_hands = mp.solutions.hands\n",
    "        self.mp_drawing = mp.solutions.drawing_utils\n",
    "        self.hands = self.mp_hands.Hands(min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "\n",
    "    def detect_hands(self, frame, draw=True):\n",
    "        rgb_img = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        self.results = self.hands.process(rgb_img)\n",
    "        if self.results.multi_hand_landmarks:\n",
    "            for hand_landmarks in self.results.multi_hand_landmarks:\n",
    "                if draw:\n",
    "                    self.mp_drawing.draw_landmarks(\n",
    "                        frame, hand_landmarks, self.mp_hands.HAND_CONNECTIONS,\n",
    "                        self.mp_drawing.DrawingSpec(color=(245, 120, 66), thickness=2, circle_radius=2),\n",
    "                        self.mp_drawing.DrawingSpec(color=(245, 66, 230), thickness=2, circle_radius=2)\n",
    "                    )\n",
    "\n",
    "        return frame\n",
    "\n",
    "    def find_hand_positions(self, frame, handNo=0, draw=True):\n",
    "        lm_list = []\n",
    "        if self.results.multi_hand_landmarks:\n",
    "            my_hand = self.results.multi_hand_landmarks[handNo]\n",
    "            for Id, lm in enumerate(my_hand.landmark):\n",
    "                h, w, c = frame.shape\n",
    "                cx, cy = int(lm.x * w), int(lm.y * h)\n",
    "                lm_list.append([Id, cx, cy])\n",
    "                if draw:\n",
    "                    cv2.circle(frame, (cx, cy), 5, (255, 0, 255), cv2.FILLED)\n",
    "\n",
    "        return lm_list\n",
    "\n",
    "    def detect_fingers(self, frame):\n",
    "        fingers_up = [0, 0, 0, 0, 0]  # Thumb, Index, Middle, Ring, Little\n",
    "        if self.results.multi_hand_landmarks:\n",
    "            hand_landmarks = self.results.multi_hand_landmarks[0]\n",
    "\n",
    "            # Debugging: Print thumb tip and base coordinates\n",
    "            thumb_tip = hand_landmarks.landmark[4]\n",
    "            thumb_base = hand_landmarks.landmark[5]\n",
    "            \n",
    "\n",
    "            # Thumb (Based on the position of thumb tip and base)\n",
    "            if thumb_tip.y <= thumb_base.y:  # If thumb tip is above thumb base\n",
    "                fingers_up[0] = 1\n",
    "\n",
    "            # Other fingers (Based on the position of finger tip and base)\n",
    "            for finger_id in range(1, 5):\n",
    "                finger_tip = hand_landmarks.landmark[finger_id * 4 + 4]\n",
    "                finger_base = hand_landmarks.landmark[finger_id * 4 +1]\n",
    "                \n",
    "                if finger_tip.y < finger_base.y:  # If finger tip is above finger base\n",
    "                    fingers_up[finger_id] = 1\n",
    "\n",
    "        return fingers_up\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34488d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Button():\n",
    "    def __init__(self, pos, text, size=[50,50]):\n",
    "        self.pos = pos \n",
    "        self.size = size\n",
    "        self.text = text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "802d0f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = [[\"Q\",\"W\",\"E\",\"R\",\"T\",\"Y\",\"U\",\"I\",\"O\",\"P\"]\n",
    "       ,[\"A\",\"S\",\"D\",\"F\",\"G\",\"H\",\"J\",\"K\",\"L\",\";\"]\n",
    "       ,[\"Z\",\"X\",\"C\",\"V\",\"B\",\"N\",\"M\",\",\",\".\",\"/\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "720915b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drawing the buttons \n",
    "\n",
    "def draw_buttons(img, buttons):\n",
    "    for button in buttons:\n",
    "        x, y = button.pos\n",
    "        w, h = button.size\n",
    "        cv2.rectangle(img, button.pos, (x + w, y + h), (255, 0, 255), cv2.FILLED)\n",
    "        cv2.putText(img, button.text, (x + 14, y + 36), cv2.FONT_HERSHEY_PLAIN, 2, (255, 255, 255), 2)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8bedc4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "buttons = []\n",
    "\n",
    "for i in range(len(keys)):\n",
    "    for j, key in enumerate(keys[i]):\n",
    "        buttons.append(Button([60*j+25, 60*i+25], key))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691a90ad",
   "metadata": {},
   "source": [
    "# Hand Gesture Recognition and Virtual Keyboard Control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75213bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = HandDetector()\n",
    "cap = cv2.VideoCapture(0)\n",
    "final_text =\"\"\n",
    "\n",
    "while cap.isOpened():\n",
    "    \n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    frame = detector.detect_hands(frame)\n",
    "    \n",
    "    frame = draw_buttons(frame, buttons) \n",
    "    lm_list = detector.find_hand_positions(frame, draw=False)\n",
    "    fingers = detector.detect_fingers(frame)\n",
    "    \n",
    "    if lm_list:\n",
    "        for button in buttons:\n",
    "            x, y = button.pos\n",
    "            w, h = button.size\n",
    "            if x < lm_list[8][1] < x + w and y<lm_list[8][2]<y+h:\n",
    "                cv2.rectangle(frame, button.pos, (x + w, y + h), (175, 0, 175), cv2.FILLED)\n",
    "                cv2.putText(frame, button.text, (x + 14, y + 36), cv2.FONT_HERSHEY_PLAIN, 2, (255, 255, 255), 2)\n",
    "                \n",
    "                if fingers[1] == 1 and fingers[2] == 1:\n",
    "                    cv2.rectangle(frame, button.pos, (x + w, y + h), (0, 255, 0), cv2.FILLED)\n",
    "                    cv2.putText(frame, button.text, (x + 14, y + 36), cv2.FONT_HERSHEY_PLAIN, 2, (255, 255, 255), 2)\n",
    "                    final_text +=button.text\n",
    "                    time.sleep(0.5)\n",
    "                    \n",
    "    cv2.rectangle(frame, (50,350), (600,450), (175, 0, 175), cv2.FILLED)\n",
    "    cv2.putText(frame, final_text, (60,425), cv2.FONT_HERSHEY_PLAIN, 2, (255, 255, 255), 2)\n",
    "    # Display\n",
    "    cv2.imshow('frame', frame)\n",
    "    \n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795f69ca",
   "metadata": {},
   "source": [
    "# Hand Gesture Recognition and Virtual Mouse Control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a6247c",
   "metadata": {},
   "outputs": [],
   "source": [
    "preTime = 0\n",
    "curTime = 0\n",
    "detector = HandDetector()\n",
    "\n",
    "# Screen resolution\n",
    "wScreen, hScreen = pyautogui.size()\n",
    "# Webcam resolution\n",
    "wCam, hCam = 1028, 840\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    \n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    frame = detector.detect_hands(frame)\n",
    "    \n",
    "    # Get the tip of the index\n",
    "    m_list = detector.find_hand_positions(frame, handNo=0, draw=False)\n",
    "    \n",
    "    if len(m_list) != 0:\n",
    "        x1, y1 = m_list[8][1:]  # Index finger tip\n",
    "        \n",
    "        # Check which fingers are up\n",
    "        fingers = detector.detect_fingers(frame)\n",
    "        \n",
    "        # Move the cursor\n",
    "        if fingers[1] == 1 and fingers[2] == 0:\n",
    "            # Interpolate the x-coordinate to screen resolution\n",
    "            x3 = np.interp(x1, (0, wCam), (0, wScreen))\n",
    "            # Interpolate the y-coordinate to screen resolution\n",
    "            y3 = np.interp(y1, (0, hCam), (0, hScreen))\n",
    "            \n",
    "            pyautogui.moveTo(wScreen-x3, y3)\n",
    "            cv2.circle(frame,(x1,y1),15,(255,0,255),cv2.FILLED)\n",
    "        # click     \n",
    "        if fingers[1] == 1 and fingers[2] == 1 and fingers[3] == 0:\n",
    "            pyautogui.click(clicks=1)\n",
    "            time.sleep(0.15)\n",
    "            \n",
    "        #scroll    \n",
    "        if fingers[1] == 1 and fingers[2] == 1 and fingers[3] == 1:\n",
    "            pyautogui.scroll(10)\n",
    "            \n",
    "    # FPS rate\n",
    "    curTime = time.time()\n",
    "    fps = 1 / (curTime - preTime)\n",
    "    preTime = curTime\n",
    "\n",
    "    cv2.putText(frame, f\"FPS: {int(fps)}\", (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (245, 117, 66), 2, cv2.LINE_AA)\n",
    "    \n",
    "    # Display\n",
    "    cv2.imshow('frame', frame)\n",
    "    \n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
